{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Connection.__del__ at 0x00000183C238B010>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rauli\\anaconda3\\envs\\IA\\lib\\site-packages\\pypyodbc.py\", line 2682, in __del__\n",
      "    self.close()\n",
      "  File \"c:\\Users\\rauli\\anaconda3\\envs\\IA\\lib\\site-packages\\pypyodbc.py\", line 2695, in close\n",
      "    self.rollback()\n",
      "  File \"c:\\Users\\rauli\\anaconda3\\envs\\IA\\lib\\site-packages\\pypyodbc.py\", line 2618, in rollback\n",
      "    check_success(self, ret)\n",
      "  File \"c:\\Users\\rauli\\anaconda3\\envs\\IA\\lib\\site-packages\\pypyodbc.py\", line 1009, in check_success\n",
      "    ctrl_err(SQL_HANDLE_DBC, ODBC_obj.dbc_h, ret, ODBC_obj.ansi)\n",
      "  File \"c:\\Users\\rauli\\anaconda3\\envs\\IA\\lib\\site-packages\\pypyodbc.py\", line 987, in ctrl_err\n",
      "    raise DatabaseError(state,err_text)\n",
      "pypyodbc.DatabaseError: ('08S01', '[08S01] [Microsoft][ODBC Driver 18 for SQL Server]TCP Provider: Se ha forzado la interrupción de una conexión existente por el host remoto.\\r\\n')\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "import pypyodbc\n",
    "import pandas as pd\n",
    "#Conn and credentials\n",
    "conn_str = 'Driver={ODBC Driver 18 for SQL Server};Server=tcp:servidortcprueba.database.windows.net,1433;Database=db_campechanos;Uid=adminraul;Pwd=5ccu9$j$XzhNMMF;Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;'\n",
    "connection = pypyodbc.connect(conn_str)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "#Training dataset\n",
    "query = \"SELECT * FROM train\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df_train = pd.DataFrame(rows)\n",
    "\n",
    "columns = [column[0] for column in cursor.description]\n",
    "df_train.columns = columns\n",
    "\n",
    "#Test dataset, dont have sales price\n",
    "query = \"SELECT * FROM test\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df_test = pd.DataFrame(rows)\n",
    "\n",
    "columns = [column[0] for column in cursor.description]\n",
    "df_test.columns = columns\n",
    "\n",
    "#Sample dataset, id and sales price\n",
    "query = \"SELECT * FROM sample\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df_sample = pd.DataFrame(rows)\n",
    "\n",
    "columns = [column[0] for column in cursor.description]\n",
    "df_sample.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_test.drop('na_mszoning',axis=1)\n",
    "df_test= df_test.drop('na_saletype',axis=1)\n",
    "columns_in_test = df_test.columns\n",
    "\n",
    "# Filtra las columnas en df_train que también están en df_test\n",
    "df_train_filtered = df_train[columns_in_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('saleprice', axis=1)  # Ajusta 'target_column' a tu columna objetivo real\n",
    "y_train = df_train['saleprice']\n",
    "\n",
    "X_train=X_train.drop('is_house_25fstory',axis=1)\n",
    "columns_in_train = X_train.columns\n",
    "\n",
    "# Filtra las columnas en df_test que también están en df_train\n",
    "df_test_filtered = df_test[columns_in_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rauli\\OneDrive\\Documentos\\Python Programs\\IA-House-Prices\\models\\house-prices-advanced-regression-techniques\\Tree_Tests(1100).ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rauli/OneDrive/Documentos/Python%20Programs/IA-House-Prices/models/house-prices-advanced-regression-techniques/Tree_Tests%281100%29.ipynb#W4sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Crea y entrena el modelo de árbol de regresión con los parámetros aleatorios\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rauli/OneDrive/Documentos/Python%20Programs/IA-House-Prices/models/house-prices-advanced-regression-techniques/Tree_Tests%281100%29.ipynb#W4sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m regression_model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBRegressor(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rauli/OneDrive/Documentos/Python%20Programs/IA-House-Prices/models/house-prices-advanced-regression-techniques/Tree_Tests%281100%29.ipynb#W4sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     objective\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mreg:squarederror\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rauli/OneDrive/Documentos/Python%20Programs/IA-House-Prices/models/house-prices-advanced-regression-techniques/Tree_Tests%281100%29.ipynb#W4sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     n_estimators\u001b[39m=\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rauli/OneDrive/Documentos/Python%20Programs/IA-House-Prices/models/house-prices-advanced-regression-techniques/Tree_Tests%281100%29.ipynb#W4sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     random_state\u001b[39m=\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mrandom_state\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rauli/OneDrive/Documentos/Python%20Programs/IA-House-Prices/models/house-prices-advanced-regression-techniques/Tree_Tests%281100%29.ipynb#W4sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rauli/OneDrive/Documentos/Python%20Programs/IA-House-Prices/models/house-prices-advanced-regression-techniques/Tree_Tests%281100%29.ipynb#W4sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m regression_model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rauli/OneDrive/Documentos/Python%20Programs/IA-House-Prices/models/house-prices-advanced-regression-techniques/Tree_Tests%281100%29.ipynb#W4sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# Realiza predicciones en el conjunto de prueba\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rauli/OneDrive/Documentos/Python%20Programs/IA-House-Prices/models/house-prices-advanced-regression-techniques/Tree_Tests%281100%29.ipynb#W4sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m y_pred \u001b[39m=\u001b[39m regression_model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\rauli\\anaconda3\\envs\\IA\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rauli\\anaconda3\\envs\\IA\\lib\\site-packages\\xgboost\\sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1014\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m (\n\u001b[0;32m   1017\u001b[0m     model,\n\u001b[0;32m   1018\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1024\u001b[0m )\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1026\u001b[0m     params,\n\u001b[0;32m   1027\u001b[0m     train_dmatrix,\n\u001b[0;32m   1028\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1029\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1030\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1031\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1032\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1033\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1034\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1035\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1036\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1037\u001b[0m )\n\u001b[0;32m   1039\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1040\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rauli\\anaconda3\\envs\\IA\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rauli\\anaconda3\\envs\\IA\\lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rauli\\anaconda3\\envs\\IA\\lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[0;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[0;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X_test = df_test_filtered\n",
    "y_test = df_sample['saleprice']\n",
    "\n",
    "best_mse = float('inf')  # Inicializa el mejor MSE con un valor infinito\n",
    "best_r2 = -float('inf')  # Inicializa el mejor R^2 con un valor negativo infinito\n",
    "best_pred = None\n",
    "\n",
    "max_tries = 100\n",
    "params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.1,\n",
    "    'random_state': 0\n",
    "}\n",
    "\n",
    "condition = False\n",
    "count=1\n",
    "\n",
    "r2_cond= -20\n",
    "mse_cond= 504500003155.638916\n",
    "\n",
    "max_tries=range(0,50)\n",
    "\n",
    "for _ in max_tries:\n",
    "    # Actualiza los parámetros con valores aleatorios\n",
    "    params['n_estimators'] = random.randint(10, 1000)\n",
    "    params['max_depth'] = random.randint(3, 1000)\n",
    "    params['learning_rate'] = random.uniform(0.005, 1.0)\n",
    "    params['random_state'] = random.randint(0, 1000)\n",
    "\n",
    "    # Crea y entrena el modelo de árbol de regresión con los parámetros aleatorios\n",
    "    regression_model = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=params['n_estimators'],\n",
    "        max_depth=params['max_depth'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        random_state=params['random_state']\n",
    "    )\n",
    "    regression_model.fit(X_train, y_train)\n",
    "\n",
    "    # Realiza predicciones en el conjunto de prueba\n",
    "    y_pred = regression_model.predict(X_test)\n",
    "\n",
    "    # Evalúa el rendimiento del modelo\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    if mse<best_mse:\n",
    "        best_pred = y_pred\n",
    "        best_r2 = r2\n",
    "        best_mse = mse\n",
    "        best_params = params.copy()\n",
    "\n",
    "print(\"Mejores hiperparámetros:\")\n",
    "print(best_params)\n",
    "print(f\"Error cuadrático medio (MSE): {best_mse}\")\n",
    "print(f\"Coeficiente de determinación (R^2): {best_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio (MSE): 4.884620815248097\n",
      "Coeficiente de determinación (R^2): -16.91421427509967\n"
     ]
    }
   ],
   "source": [
    "past_r2= best_r2\n",
    "past_mse = best_mse\n",
    "past_pred=best_pred\n",
    "print(f\"Error cuadrático medio (MSE): {past_mse/1000000000}\")\n",
    "print(f\"Coeficiente de determinación (R^2): {past_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros:\n",
      "{'n_estimators': 77, 'max_depth': 40, 'learning_rate': 0.22814120619150743, 'subsample': 0.806824415097525, 'colsample_bytree': 0.5104388057298872, 'gamma': 0.8288938864702186, 'reg_alpha': 0.9945293821785826, 'reg_lambda': 0.28198489972784424, 'min_child_weight': 2.302200931051233, 'random_state': 643}\n",
      "Error cuadrático medio (MSE): 5.079498413271502\n",
      "Coeficiente de determinación (R^2): -17.628922577023552\n"
     ]
    }
   ],
   "source": [
    "#More Hiperparameters\n",
    "import random\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X_test = df_test_filtered\n",
    "y_test = df_sample['saleprice']\n",
    "\n",
    "best_mse_hip = float('inf')  # Inicializa el mejor MSE con un valor infinito\n",
    "best_r2_hip = -float('inf')  # Inicializa el mejor R^2 con un valor negativo infinito\n",
    "best_pred_hip = None\n",
    "\n",
    "max_tries = 50\n",
    "\n",
    "for _ in range(max_tries):\n",
    "    # Genera valores aleatorios para todos los hiperparámetros posibles\n",
    "    params = {\n",
    "        'n_estimators': random.randint(10, 1000),\n",
    "        'max_depth': random.randint(3, 100),\n",
    "        'learning_rate': random.uniform(0.001, 1.0),\n",
    "        'subsample': random.uniform(0.5, 1.0),\n",
    "        'colsample_bytree': random.uniform(0.5, 1.0),\n",
    "        'gamma': random.uniform(0, 1.0),\n",
    "        'reg_alpha': random.uniform(0, 1.0),\n",
    "        'reg_lambda': random.uniform(0, 1.0),\n",
    "        'min_child_weight': random.uniform(1, 10),\n",
    "        'random_state': random.randint(0, 1000)\n",
    "    }\n",
    "\n",
    "    # Crea y entrena el modelo de árbol de regresión con los parámetros aleatorios\n",
    "    regression_model = xgb.XGBRegressor(**params, objective='reg:squarederror')\n",
    "    regression_model.fit(X_train, y_train)\n",
    "\n",
    "    # Realiza predicciones en el conjunto de prueba\n",
    "    y_pred = regression_model.predict(X_test)\n",
    "\n",
    "    # Evalúa el rendimiento del modelo\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    if mse < best_mse_hip:\n",
    "        best_pred_hip = y_pred\n",
    "        best_r2_hip = r2\n",
    "        best_mse_hip = mse\n",
    "        best_params_hip = params.copy()\n",
    "\n",
    "print(\"Mejores hiperparámetros:\")\n",
    "print(best_params_hip)\n",
    "print(f\"Error cuadrático medio (MSE): {best_mse_hip/1000000000}\")\n",
    "print(f\"Coeficiente de determinación (R^2): {best_r2_hip}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor Score del modelo: -18.396516091260402\n",
      "Mejor Error cuadrático medio (MSE): 5288796080.459861\n",
      "Mejor Coeficiente de determinación (R^2): -18.396516091260402\n",
      "Mejor Random: 1\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define el rango de random_state que deseas probar\n",
    "random_state_range = range(1, 101)  # Por ejemplo, prueba valores de 1 a 100\n",
    "\n",
    "best_model = None\n",
    "best_score = -float('inf')  # Inicializa el mejor score con un valor negativo infinito\n",
    "\n",
    "for random_state in random_state_range:\n",
    "    # Crea un modelo XGBoost con el valor actual de random_state\n",
    "    model = xgb.XGBRegressor(random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Calcula el score del modelo en el conjunto de prueba\n",
    "    model_score = model.score(X_test, y_test)\n",
    "\n",
    "    # Actualiza el mejor modelo si se encuentra un modelo con un mejor score\n",
    "    if model_score > best_score:\n",
    "        best_score = model_score\n",
    "        best_model = model\n",
    "        best_r = random_state\n",
    "\n",
    "# Realiza predicciones en el conjunto de prueba usando el mejor modelo\n",
    "best_model_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcula el MSE y R^2 del mejor modelo\n",
    "best_mse = mean_squared_error(y_test, best_model_pred)\n",
    "best_r2 = r2_score(y_test, best_model_pred)\n",
    "\n",
    "# Imprime el mejor score y las métricas del mejor modelo\n",
    "print(f\"Mejor Score del modelo: {best_score}\")\n",
    "print(f\"Mejor Error cuadrático medio (MSE): {best_mse}\")\n",
    "print(f\"Mejor Coeficiente de determinación (R^2): {best_r2}\")\n",
    "print(f\"Mejor Random: {best_r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame({'id': df_sample['id'], 'SalePrice': best_model_pred})\n",
    "\n",
    "# Guarda el DataFrame resultante en un archivo CSV\n",
    "df_predictions.to_csv('Ppredicciones.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
